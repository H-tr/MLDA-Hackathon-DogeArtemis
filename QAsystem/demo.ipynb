{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/run/.miniconda3/envs/hackathon/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'dataset_info': token. Will not be supported from version '0.12'.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using custom data configuration default\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the dataset from huggingface in streaming mode and shuffle it\n",
    "wiki_data = load_dataset(\n",
    "    'vblagoje/wikipedia_snippets_streamed',\n",
    "    split='train',\n",
    "    streaming=True\n",
    ").shuffle(seed=960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wiki_id': 'Q7649565',\n",
       " 'start_paragraph': 20,\n",
       " 'start_character': 272,\n",
       " 'end_paragraph': 24,\n",
       " 'end_character': 380,\n",
       " 'article_title': 'Sustainable Agriculture Research and Education',\n",
       " 'section_title': \"2000s & Evaluation of the program's effectiveness\",\n",
       " 'passage_text': \"preserving the surrounding prairies. It ran until March 31, 2001.\\nIn 2008, SARE celebrated its 20th anniversary. To that date, the program had funded 3,700 projects and was operating with an annual budget of approximately $19 million. Evaluation of the program's effectiveness As of 2008, 64% of farmers who had received SARE grants stated that they had been able to earn increased profits as a result of the funding they received and utilization of sustainable agriculture methods. Additionally, 79% of grantees said that they had experienced a significant improvement in soil quality though the environmentally friendly, sustainable methods that they were\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(wiki_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter only documents with History as section_title\n",
    "history = wiki_data.filter(\n",
    "    lambda d: d['section_title'].startswith('History')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5232a72105ca4cf99e71d6a8aeb7097d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm  # progress bar\n",
    "\n",
    "total_doc_count = 50000\n",
    "\n",
    "counter = 0\n",
    "docs = []\n",
    "# iterate through the dataset and apply our filter\n",
    "for d in tqdm(history, total=total_doc_count):\n",
    "    # extract the fields we need\n",
    "    doc = {\n",
    "        \"article_title\": d[\"article_title\"],\n",
    "        \"section_title\": d[\"section_title\"],\n",
    "        \"passage_text\": d[\"passage_text\"]\n",
    "    }\n",
    "    # add the dict containing fields we need to docs list\n",
    "    docs.append(doc)\n",
    "\n",
    "    # stop iteration once we reach 50k\n",
    "    if counter == total_doc_count:\n",
    "        break\n",
    "\n",
    "    # increase the counter on every iteration\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>section_title</th>\n",
       "      <th>passage_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taupo District</td>\n",
       "      <td>History</td>\n",
       "      <td>was not until the 1950s that the region starte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sutarfeni</td>\n",
       "      <td>History &amp; Western asian analogues</td>\n",
       "      <td>Sutarfeni History strand-like pheni were Phena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Bishop Wand Church of England School</td>\n",
       "      <td>History</td>\n",
       "      <td>The Bishop Wand Church of England School Histo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Teufelsmoor</td>\n",
       "      <td>History &amp; Situation today</td>\n",
       "      <td>made to preserve the original landscape, altho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Surface Hill Uniting Church</td>\n",
       "      <td>History</td>\n",
       "      <td>in perpetual reminder that work and worship go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              article_title  \\\n",
       "0                            Taupo District   \n",
       "1                                 Sutarfeni   \n",
       "2  The Bishop Wand Church of England School   \n",
       "3                               Teufelsmoor   \n",
       "4               Surface Hill Uniting Church   \n",
       "\n",
       "                       section_title  \\\n",
       "0                            History   \n",
       "1  History & Western asian analogues   \n",
       "2                            History   \n",
       "3          History & Situation today   \n",
       "4                            History   \n",
       "\n",
       "                                        passage_text  \n",
       "0  was not until the 1950s that the region starte...  \n",
       "1  Sutarfeni History strand-like pheni were Phena...  \n",
       "2  The Bishop Wand Church of England School Histo...  \n",
       "3  made to preserve the original landscape, altho...  \n",
       "4  in perpetual reminder that work and worship go...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a pandas dataframe with the documents we extracted\n",
    "df = pd.DataFrame(docs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# connect to pinecone environment\n",
    "pinecone.init(\n",
    "    api_key=\"442d1d81-beba-41f7-8510-f732c8fff44c\",\n",
    "    environment=\"us-west1-gcp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"abstractive-question-answering\"\n",
    "\n",
    "# check if the abstractive-question-answering index exists\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # create the index if it does not exist\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    "\n",
    "# connect to abstractive-question-answering index we created\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44357c599c354ece91bf96ad5332dfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/737 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248c08ad48e54b668337b9bcb6b8634b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7252da67454164b2e2af4f9598c893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13121fba1b348e99018532c3a3bd555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/591 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c488973f07489f954e7434696ef9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91255cda0d324a1abefeb7dad568d375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/15.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e42492affd849df8b7e9fe518b0dd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960b8108b6ff4bedbed26734de76fb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae69fd0b87c34e57b0a8231bb8b43fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c090f9082a134ca2bf094118c1e3c4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5dd65b3eda449dfb017a9a9f3e3d8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/383 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8289f40fab241e7b5ccbc77219b94c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d427a4813cfa4329bff600a1cf4bf93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098af96f337e43a990408f6fe1fe8021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# load the retriever model from huggingface model hub\n",
    "retriever = SentenceTransformer(\"flax-sentence-embeddings/all_datasets_v3_mpnet-base\")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc8632528724fcd9f7fa55777e0f6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.1,\n",
       " 'namespaces': {'': {'vector_count': 50001}},\n",
       " 'total_vector_count': 50001}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use batches of 64\n",
    "batch_size = 64\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(i+batch_size, len(df))\n",
    "    # extract batch\n",
    "    batch = df.iloc[i:i_end]\n",
    "    # generate embeddings for batch\n",
    "    emb = retriever.encode(batch[\"passage_text\"].tolist()).tolist()\n",
    "    # get metadata\n",
    "    meta = batch.to_dict(orient=\"records\")\n",
    "    # create unique IDs\n",
    "    ids = [f\"{idx}\" for idx in range(i, i_end)]\n",
    "    # add all to upsert list\n",
    "    to_upsert = list(zip(ids, emb, meta))\n",
    "    # upsert/insert these records to pinecone\n",
    "    _ = index.upsert(vectors=to_upsert)\n",
    "\n",
    "# check that we have all vectors in index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d283e3ebc7472eb23da3c252597e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f9cc3a7b42408a8045058fb124b9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7e617638714d419fb634022e73a684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1456fa611dd44545b56878ca2a71e154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b781630bd454fac897530679d1d0b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# load bart tokenizer and model from huggingface\n",
    "tokenizer = BartTokenizer.from_pretrained('vblagoje/bart_lfqa')\n",
    "generator = BartForConditionalGeneration.from_pretrained('vblagoje/bart_lfqa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pinecone(query, top_k):\n",
    "    # generate embeddings for the query\n",
    "    xq = retriever.encode([query]).tolist()\n",
    "    # search pinecone index for context passage with the answer\n",
    "    xc = index.query(xq, top_k=top_k, include_metadata=True)\n",
    "    return xc\n",
    "\n",
    "def format_query(query, context):\n",
    "    # extract passage_text from Pinecone search result and add the <P> tag\n",
    "    context = [f\"<P> {m['metadata']['passage_text']}\" for m in context]\n",
    "    # concatinate all context passages\n",
    "    context = \" \".join(context)\n",
    "    # contcatinate the query and context passages\n",
    "    query = f\"question: {query} context: {context}\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '3593',\n",
       "              'metadata': {'article_title': 'Electric power system',\n",
       "                           'passage_text': 'Electric power system History In '\n",
       "                                           '1881, two electricians built the '\n",
       "                                           \"world's first power system at \"\n",
       "                                           'Godalming in England. It was '\n",
       "                                           'powered by two waterwheels and '\n",
       "                                           'produced an alternating current '\n",
       "                                           'that in turn supplied seven '\n",
       "                                           'Siemens arc lamps at 250 volts and '\n",
       "                                           '34 incandescent lamps at 40 volts. '\n",
       "                                           'However, supply to the lamps was '\n",
       "                                           'intermittent and in 1882 Thomas '\n",
       "                                           'Edison and his company, The Edison '\n",
       "                                           'Electric Light Company, developed '\n",
       "                                           'the first steam-powered electric '\n",
       "                                           'power station on Pearl Street in '\n",
       "                                           'New York City. The Pearl Street '\n",
       "                                           'Station initially powered around '\n",
       "                                           '3,000 lamps for 59 customers. The '\n",
       "                                           'power station generated direct '\n",
       "                                           'current and',\n",
       "                           'section_title': 'History'},\n",
       "              'score': 0.69118005,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"when was the first electric power system built?\"\n",
    "result = query_pinecone(query, top_k=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('question: when was the first electric power system built? context: <P> '\n",
      " \"Electric power system History In 1881, two electricians built the world's \"\n",
      " 'first power system at Godalming in England. It was powered by two '\n",
      " 'waterwheels and produced an alternating current that in turn supplied seven '\n",
      " 'Siemens arc lamps at 250 volts and 34 incandescent lamps at 40 volts. '\n",
      " 'However, supply to the lamps was intermittent and in 1882 Thomas Edison and '\n",
      " 'his company, The Edison Electric Light Company, developed the first '\n",
      " 'steam-powered electric power station on Pearl Street in New York City. The '\n",
      " 'Pearl Street Station initially powered around 3,000 lamps for 59 customers. '\n",
      " 'The power station generated direct current and')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# format the query in the form generator expects the input\n",
    "query = format_query(query, result[\"matches\"])\n",
    "pprint(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query):\n",
    "    # tokenize the query to get input_ids\n",
    "    inputs = tokenizer([query], max_length=1024, return_tensors=\"pt\")\n",
    "    # use generator to predict output ids\n",
    "    ids = generator.generate(inputs[\"input_ids\"], num_beams=2, min_length=20, max_length=40)\n",
    "    # use tokenizer to decode the output ids\n",
    "    answer = tokenizer.batch_decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    return pprint(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "2022-10-01 15:08:02.283903: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-01 15:08:05.871547: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-01 15:08:12.444671: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:\n",
      "2022-10-01 15:08:12.447331: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:\n",
      "2022-10-01 15:08:12.447342: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The first electric power system was built in 1881 at Godalming in England. '\n",
      " 'It was powered by two waterwheels and produced alternating current that in '\n",
      " 'turn supplied seven Siemens arc lamps')\n"
     ]
    }
   ],
   "source": [
    "generate_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The first wireless message was sent in 1866 by Mahlon Loomis, who had a kite '\n",
      " 'on a mountaintop 14 miles apart. The kite was connected to a cable')\n"
     ]
    }
   ],
   "source": [
    "query = \"How was the first wireless message sent?\"\n",
    "context = query_pinecone(query, top_k=5)\n",
    "query = format_query(query, context[\"matches\"])\n",
    "generate_answer(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('hackathon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9de89fd9b00c0d9938d74636bda9d8749cea044c4a50df9ee236df98ebfcbf20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
